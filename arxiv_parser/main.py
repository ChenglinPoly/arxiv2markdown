#!/usr/bin/env python3
"""
arXivè®ºæ–‡æ‰¹é‡è½¬æ¢å·¥å…·
å°†PDFå’ŒTeXå‹ç¼©åŒ…è½¬æ¢ä¸ºç»“æ„åŒ–çš„Markdownæ–‡ä»¶
"""

import os
import sys
from pathlib import Path
from typing import List, Tuple

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from arxiv_parser.config import (
    ensure_directories, 
    SOURCE_DIR, 
    OUTPUT_DIR, 
    FAILED_DIR, 
    TEMP_DIR,
    SUPPORTED_PDF_EXTENSIONS,
    SUPPORTED_TEX_EXTENSIONS
)
from arxiv_parser.utils.logger import setup_logger
from arxiv_parser.utils.file_system import safe_move_to_failed
from arxiv_parser.processors import tex_processor

logger = setup_logger("main")

def get_file_type(file_path: Path) -> str:
    """
    ç¡®å®šæ–‡ä»¶ç±»å‹
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        
    Returns:
        æ–‡ä»¶ç±»å‹ï¼š'pdf', 'tex', æˆ– 'unknown'
    """
    suffix = file_path.suffix.lower()
    
    if suffix in SUPPORTED_PDF_EXTENSIONS:
        return 'pdf'
    elif suffix in SUPPORTED_TEX_EXTENSIONS or file_path.name.endswith('.tar.gz'):
        return 'tex'
    else:
        return 'unknown'

def process_single_file(file_path: Path) -> Tuple[bool, str]:
    """
    å¤„ç†å•ä¸ªæ–‡ä»¶ï¼ˆä¸åŒ…å«å¤±è´¥æ–‡ä»¶ç§»åŠ¨é€»è¾‘ï¼‰
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        
    Returns:
        (å¤„ç†æ˜¯å¦æˆåŠŸ, é”™è¯¯ä¿¡æ¯)
    """
    logger.info(f"å¼€å§‹å¤„ç†æ–‡ä»¶: {file_path.name}")
    
    file_type = get_file_type(file_path)
    
    try:
        if file_type == 'pdf':
            logger.info(f"ğŸš« è·³è¿‡PDFæ–‡ä»¶: {file_path.name} (ä»…å¤„ç†TeXå‹ç¼©åŒ…)")
            return False, "è·³è¿‡PDFæ–‡ä»¶ (ä»…å¤„ç†TeXå‹ç¼©åŒ…)"
        elif file_type == 'tex':
            success, error_msg = tex_processor.process(file_path, OUTPUT_DIR, TEMP_DIR)
            if success:
                logger.info(f"æˆåŠŸå¤„ç†æ–‡ä»¶: {file_path.name}")
                return True, ""
            else:
                logger.error(f"å¤„ç†æ–‡ä»¶å¤±è´¥: {file_path.name}")
                return False, error_msg
        else:
            error_msg = f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_path.suffix}"
            logger.warning(f"è·³è¿‡ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_path.name}")
            return False, error_msg
            
    except Exception as e:
        error_msg = f"å¤„ç†å¼‚å¸¸: {str(e)}"
        logger.error(f"å¤„ç†æ–‡ä»¶ {file_path.name} æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
        return False, error_msg

def process_single_file_with_failover(file_path: Path) -> bool:
    """
    å¤„ç†å•ä¸ªæ–‡ä»¶å¹¶åœ¨å¤±è´¥æ—¶ç§»åŠ¨åˆ°failedç›®å½•
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        
    Returns:
        å¤„ç†æ˜¯å¦æˆåŠŸ
    """
    success, error_msg = process_single_file(file_path)
    
    if not success:
        # ç«‹å³å°†å¤±è´¥çš„æ–‡ä»¶ç§»åŠ¨åˆ°å¤±è´¥ç›®å½•ï¼Œå¹¶è®°å½•é”™è¯¯ä¿¡æ¯
        logger.warning(f"æ–‡ä»¶å¤„ç†å¤±è´¥ï¼Œç«‹å³ç§»åŠ¨åˆ°å¤±è´¥ç›®å½•: {file_path.name}")
        
        # æ¸…ç†å¯èƒ½å·²åˆ›å»ºçš„è¾“å‡ºç›®å½•
        cleanup_failed_output_directory(file_path)
        
        if safe_move_to_failed(file_path, FAILED_DIR, error_msg):
            logger.info(f"âœ… å·²ç§»åŠ¨å¤±è´¥æ–‡ä»¶: {file_path.name} -> failed/")
        else:
            logger.error(f"âŒ ç§»åŠ¨å¤±è´¥æ–‡ä»¶æ—¶å‡ºé”™: {file_path.name}")
    
    return success

def cleanup_failed_output_directory(file_path: Path):
    """
    æ¸…ç†å¤±è´¥æ–‡ä»¶å¯èƒ½å·²åˆ›å»ºçš„è¾“å‡ºç›®å½•
    
    Args:
        file_path: åŸå§‹æ–‡ä»¶è·¯å¾„
    """
    try:
        from .utils.file_system import get_base_name
        base_name = get_base_name(file_path)
        potential_output_dir = OUTPUT_DIR / base_name
        
        if potential_output_dir.exists():
            import shutil
            shutil.rmtree(potential_output_dir)
            logger.debug(f"å·²æ¸…ç†å¤±è´¥æ–‡ä»¶çš„è¾“å‡ºç›®å½•: {potential_output_dir}")
    except Exception as e:
        logger.warning(f"æ¸…ç†å¤±è´¥æ–‡ä»¶çš„è¾“å‡ºç›®å½•æ—¶å‡ºé”™: {e}")

def get_processing_statistics(source_dir: Path) -> Tuple[int, int, int]:
    """
    è·å–å¤„ç†ç»Ÿè®¡ä¿¡æ¯
    
    Args:
        source_dir: æºç›®å½•
        
    Returns:
        (æ€»æ–‡ä»¶æ•°, PDFæ–‡ä»¶æ•°, TeXæ–‡ä»¶æ•°)
    """
    all_files = list(source_dir.glob("*"))
    all_files = [f for f in all_files if f.is_file() and not f.name.startswith('.')]
    
    pdf_count = sum(1 for f in all_files if get_file_type(f) == 'pdf')
    tex_count = sum(1 for f in all_files if get_file_type(f) == 'tex')
    
    return len(all_files), pdf_count, tex_count

def main():
    """ä¸»å‡½æ•°"""
    logger.info("=" * 60)
    logger.info("å¼€å§‹arXivè®ºæ–‡æ‰¹é‡è½¬æ¢")
    logger.info("=" * 60)
    
    # ç¡®ä¿æ‰€æœ‰å¿…è¦ç›®å½•å­˜åœ¨
    ensure_directories()
    
    # è·å–æºç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶
    if not SOURCE_DIR.exists():
        logger.error(f"æºç›®å½•ä¸å­˜åœ¨: {SOURCE_DIR}")
        return 1
    
    all_files = list(SOURCE_DIR.glob("*"))
    # è¿‡æ»¤æ‰ç›®å½•å’Œéšè—æ–‡ä»¶
    files_to_process = [f for f in all_files if f.is_file() and not f.name.startswith('.')]
    
    if not files_to_process:
        logger.warning(f"åœ¨æºç›®å½• {SOURCE_DIR} ä¸­æœªæ‰¾åˆ°ä»»ä½•æ–‡ä»¶")
        return 0
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    total_files, pdf_count, tex_count = get_processing_statistics(SOURCE_DIR)
    logger.info(f"å‘ç°æ–‡ä»¶ç»Ÿè®¡:")
    logger.info(f"  æ€»æ–‡ä»¶æ•°: {total_files}")
    logger.info(f"  PDFæ–‡ä»¶: {pdf_count} (å°†è¢«è·³è¿‡)")
    logger.info(f"  TeXæ–‡ä»¶: {tex_count} (å°†è¢«å¤„ç†)")
    logger.info(f"  å…¶ä»–æ–‡ä»¶: {total_files - pdf_count - tex_count}")
    
    # å¤„ç†æ–‡ä»¶
    successful_count = 0
    failed_count = 0
    skipped_count = 0
    pdf_skipped_count = 0
    
    for i, file_path in enumerate(files_to_process, 1):
        logger.info(f"\nè¿›åº¦: {i}/{len(files_to_process)}")
        
        file_type = get_file_type(file_path)
        if file_type == 'unknown':
            logger.info(f"è·³è¿‡ä¸æ”¯æŒçš„æ–‡ä»¶: {file_path.name}")
            skipped_count += 1
            continue
        elif file_type == 'pdf':
            logger.info(f"ğŸš« è·³è¿‡PDFæ–‡ä»¶: {file_path.name}")
            pdf_skipped_count += 1
            continue
        
        # å¤„ç†æ–‡ä»¶ï¼ˆç°åœ¨åªå¤„ç†TeXæ–‡ä»¶ï¼‰
        success = process_single_file_with_failover(file_path)
        
        if success:
            successful_count += 1
        else:
            failed_count += 1
    
    # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
    logger.info("\n" + "=" * 60)
    logger.info("å¤„ç†å®Œæˆï¼æœ€ç»ˆç»Ÿè®¡:")
    logger.info("=" * 60)
    logger.info(f"æˆåŠŸå¤„ç†: {successful_count} ä¸ªTeXæ–‡ä»¶")
    logger.info(f"å¤„ç†å¤±è´¥: {failed_count} ä¸ªTeXæ–‡ä»¶")
    logger.info(f"è·³è¿‡PDFæ–‡ä»¶: {pdf_skipped_count} ä¸ªæ–‡ä»¶")
    logger.info(f"è·³è¿‡å…¶ä»–æ–‡ä»¶: {skipped_count} ä¸ªæ–‡ä»¶")
    
    if successful_count > 0:
        logger.info(f"\næˆåŠŸå¤„ç†çš„æ–‡ä»¶è¾“å‡ºåˆ°: {OUTPUT_DIR}")
    
    if failed_count > 0:
        logger.info("æ‚¨å¯ä»¥æ£€æŸ¥failed/ç›®å½•ä¸­çš„å¤±è´¥æ–‡ä»¶å¹¶å°è¯•æ‰‹åŠ¨å¤„ç†")
    
    # æ¸…ç†ä¸´æ—¶ç›®å½•
    if TEMP_DIR.exists():
        import shutil
        for item in TEMP_DIR.iterdir():
            if item.is_dir():
                shutil.rmtree(item)
            else:
                item.unlink()
        logger.info("å·²æ¸…ç†ä¸´æ—¶ç›®å½•")
    
    logger.info("\nè½¬æ¢ä»»åŠ¡å®Œæˆï¼")
    
    return 0 if failed_count == 0 else 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code) 